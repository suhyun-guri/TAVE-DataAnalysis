{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.input_area pre {font-family: Consolas; font-size: 12pt; line-height: 140%;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_area pre {font-family: Consolas; font-size: 12pt; line-height: 140%;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "display(HTML(\"<style>.input_area pre {font-family: Consolas; font-size: 12pt; line-height: 140%;}</style>\"))\n",
    "display(HTML(\"<style>.output_area pre {font-family: Consolas; font-size: 12pt; line-height: 140%;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2) 강남역 맛집 리뷰로 알아보는 감성 분류\n",
    "### 감성 분류란 문서(텍스트 데이터)를 긍정 또는 부정 의견으로 나누어 분류하는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step1. 크롤링]: 네이버 플레이스 리뷰 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [네이버 플레이스 API] \n",
    "### 관련도순 상위 100개의 고기집 리스트 정보 API 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'select': '1', 'item': [{'rank': '1', 'region_keyword': '강남역', 'region_type': 'favor', 'r...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# 네이버 플레이스 API를 호출하기 위한 기본 주소\n",
    "source_url = \"https://store.naver.com/sogum/api/businesses?\"\n",
    "\n",
    "# 검색 규칙 파라미터 추가\n",
    "url_parameter_start = \"start=1\"\n",
    "url_parameter_display = \"&display=\"\n",
    "url_parameter_query = \"&query=강남역+고기집\"\n",
    "url_parameter_sorting = \"&sortingOrder=precision\"\n",
    "url_concat = source_url + url_parameter_start + \\\n",
    "            url_parameter_display + str(100) + url_parameter_query + url_parameter_sorting\n",
    "    \n",
    "# 반환받은 API 데이터에 json.loads 함수 사용\n",
    "json_data = requests.get(url_concat).text\n",
    "restaurant_list_data = json.loads(json_data)\n",
    "\n",
    "# 관련도순 상위 100개의 고기집 리스트 정보 출력\n",
    "print(str(restaurant_list_data)[:100]+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리뷰데이터가 아직 없으므로 랭킹 목록의 상세 페이지로 이동해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request_url: https://store.naver.com/sogum/api/businesses?start=1&display=100&query=강남역+고기집&sortingOrder=precision\n",
      "request_url: https://store.naver.com/sogum/api/businesses?start=101&display=200&query=강남역+고기집&sortingOrder=precision\n",
      "request_url: https://store.naver.com/sogum/api/businesses?start=201&display=300&query=강남역+고기집&sortingOrder=precision\n",
      "request_url: https://store.naver.com/sogum/api/businesses?start=301&display=400&query=강남역+고기집&sortingOrder=precision\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e05007a077ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mjson_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_concat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mrestaurant_list_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# 크롤링에 필요한 각 리뷰 상세 페이지의 id 추출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "restaurant_id_list = []\n",
    "\n",
    "# 100개씩의 API 호출 결과를 10번 가져온다.\n",
    "for start_idx in [1, 101, 201, 301, 401, 501, 601, 701, 801, 901]:\n",
    "    \n",
    "    # 네이버 플레이스 API를 호출하기 위한 기본 주소\n",
    "    source_url = \"https://store.naver.com/sogum/api/businesses?\"\n",
    "    \n",
    "    # 검색 규칙 파라미터 추가\n",
    "    url_parameter_start = \"start=\" + str(start_idx)\n",
    "    url_parameter_display = \"&display=\"\n",
    "    url_parameter_query = \"&query=강남역+고기집\"\n",
    "    url_parameter_sorting = \"&sortingOrder=precision\"\n",
    "    url_concat = source_url + url_parameter_start + \\\n",
    "                url_parameter_display + str(start_idx+99) + url_parameter_query + url_parameter_sorting\n",
    "    print(\"request_url:\", url_concat)\n",
    "    json_data = requests.get(url_concat).text\n",
    "\n",
    "    restaurant_list_data = json.loads(json_data)\n",
    "\n",
    "    # 크롤링에 필요한 각 리뷰 상세 페이지의 id 추출\n",
    "    for restaurant in restaurant_list_data['items']:\n",
    "        if 'moreBookingReviewsPath' in restaurant:\n",
    "            restaurant_id_list.append(restaurant['id'])\n",
    "\n",
    "restaurant_id_list = list(set(restaurant_id_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [맛집 리뷰 정보 크롤링]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [score, review]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['score', 'review']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawl 0 % complete..\n",
      "Crawl 1 % complete..\n",
      "Crawl 3 % complete..\n",
      "Crawl 5 % complete..\n",
      "Crawl 7 % complete..\n",
      "Crawl 8 % complete..\n",
      "Crawl 10 % complete..\n",
      "Crawl 12 % complete..\n",
      "Crawl 14 % complete..\n",
      "Crawl 16 % complete..\n",
      "Crawl 17 % complete..\n",
      "Crawl 19 % complete..\n",
      "Crawl 21 % complete..\n",
      "Crawl 23 % complete..\n",
      "Crawl 25 % complete..\n",
      "Crawl 26 % complete..\n",
      "Crawl 28 % complete..\n",
      "Crawl 30 % complete..\n",
      "Crawl 32 % complete..\n",
      "Crawl 33 % complete..\n",
      "Crawl 35 % complete..\n",
      "Crawl 37 % complete..\n",
      "Crawl 39 % complete..\n",
      "Crawl 41 % complete..\n",
      "Crawl 42 % complete..\n",
      "Crawl 44 % complete..\n",
      "Crawl 46 % complete..\n",
      "Crawl 48 % complete..\n",
      "Crawl 50 % complete..\n",
      "Crawl 51 % complete..\n",
      "Crawl 53 % complete..\n",
      "Crawl 55 % complete..\n",
      "Crawl 57 % complete..\n",
      "Crawl 58 % complete..\n",
      "Crawl 60 % complete..\n",
      "Crawl 62 % complete..\n",
      "Crawl 64 % complete..\n",
      "Crawl 66 % complete..\n",
      "Crawl 67 % complete..\n",
      "Crawl 69 % complete..\n",
      "Crawl 71 % complete..\n",
      "Crawl 73 % complete..\n",
      "Crawl 75 % complete..\n",
      "Crawl 76 % complete..\n",
      "Crawl 78 % complete..\n",
      "Crawl 80 % complete..\n",
      "Crawl 82 % complete..\n",
      "Crawl 83 % complete..\n",
      "Crawl 85 % complete..\n",
      "Crawl 87 % complete..\n",
      "Crawl 89 % complete..\n",
      "Crawl 91 % complete..\n",
      "Crawl 92 % complete..\n",
      "Crawl 94 % complete..\n",
      "Crawl 96 % complete..\n",
      "Crawl 98 % complete..\n",
      "Crawl 100 % complete\n"
     ]
    }
   ],
   "source": [
    "# 리뷰 상세 페이지의 기본 주소\n",
    "source_url_head = \"https://store.naver.com/restaurants/detail?id=\"\n",
    "source_url_tail = \"&tab=bookingReview#_tab\"\n",
    "\n",
    "for idx in range(0, len(restaurant_id_list)):\n",
    "    print(\"Crawl\", str(int(idx/len(restaurant_id_list)*100)), \"% complete..\")\n",
    "    \n",
    "    # 앞서 추출한 리뷰 상세 페이지의 id를 기본 주소의 파라미터로 추가\n",
    "    req = requests.get(source_url_head + str(restaurant_id_list[idx]) + source_url_tail)\n",
    "    html = req.content\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    review_area = soup.find(name=\"div\", attrs={\"class\":\"review_area\"})\n",
    "\n",
    "    # 리뷰가 없는 페이지는 아무 작업도 수행하지 않는다.\n",
    "    if review_area is None:\n",
    "        continue\n",
    "\n",
    "    # 개발자 도구로 살펴본 html 구조에서 리뷰의 점수, 텍스트 부분을 추출\n",
    "    review_list = review_area.find_all(name=\"div\", attrs={\"class\":\"info_area\"})\n",
    "    for review in review_list:\n",
    "        score = review.find(name=\"span\", attrs={\"class\":\"score\"}).text\n",
    "        review_txt = review.find(name=\"div\", attrs={\"class\":\"review_txt\"}).text\n",
    "\n",
    "        # 추출한 리뷰의 점수, 리뷰 텍스트를 데이터프레임으로 병합\n",
    "        row = [score, review_txt]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df = df.append(series, ignore_index=True)\n",
    "print(\"Crawl 100 %\", \"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>일하시는 직원분들도 너무 친절하시고🥰\\n셀프바 이용 맘에 듦😻\\n후식 free 아슈...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>직원 분들도 너무 친절하시고 맛있었어요!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>소고기 다양한 부위를 무한대로 먹을 수 있는 곳이었어요! 가성비 굿입니다!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>나만가고싶다..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>가성비로는 정말 좋아요. 3-4번 정도 리필 한 거 같구요. 배 터지게 먹었어요. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                                             review\n",
       "0     5  일하시는 직원분들도 너무 친절하시고🥰\\n셀프바 이용 맘에 듦😻\\n후식 free 아슈...\n",
       "1     5                            직원 분들도 너무 친절하시고 맛있었어요!!\n",
       "2     5          소고기 다양한 부위를 무한대로 먹을 수 있는 곳이었어요! 가성비 굿입니다!\n",
       "3     5                                           나만가고싶다..\n",
       "4     5  가성비로는 정말 좋아요. 3-4번 정도 리필 한 거 같구요. 배 터지게 먹었어요. ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>일하시는 직원분들도 너무 친절하시고🥰\\n셀프바 이용 맘에 듦😻\\n후식 free 아슈...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>직원 분들도 너무 친절하시고 맛있었어요!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>소고기 다양한 부위를 무한대로 먹을 수 있는 곳이었어요! 가성비 굿입니다!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>나만가고싶다..</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>가성비로는 정말 좋아요. 3-4번 정도 리필 한 거 같구요. 배 터지게 먹었어요. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                                             review  y\n",
       "0     5  일하시는 직원분들도 너무 친절하시고🥰\\n셀프바 이용 맘에 듦😻\\n후식 free 아슈...  1\n",
       "1     5                            직원 분들도 너무 친절하시고 맛있었어요!!  1\n",
       "2     5          소고기 다양한 부위를 무한대로 먹을 수 있는 곳이었어요! 가성비 굿입니다!  1\n",
       "3     5                                           나만가고싶다..  1\n",
       "4     5  가성비로는 정말 좋아요. 3-4번 정도 리필 한 거 같구요. 배 터지게 먹었어요. ...  1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4점 이상의 리뷰는 긍정 리뷰, 3점 이하의 리뷰는 부정 리뷰로 평가\n",
    "df['y'] = df['score'].apply(lambda x: 1 if int(float(x)) > 3 else 0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"review_data.csv\", index=False)\n",
    "df = pd.read_csv(\"review_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step2. 전처리] : TF-IDF를 이용한 핵심어 추출\n",
    "### [형태소 추출하기]\n",
    "##### 한글 텍스트로 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 텍스트 정제 함수 : 한글 이외의 문자는 전부 제거\n",
    "def text_cleaning(text):\n",
    "    # 한글의 정규표현식으로 한글만 추출\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "    result = hangul.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>y</th>\n",
       "      <th>ko_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>분위기 맛 서비스 최고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>곱창 맛집 갈때마다 만족스러운 곱창집입니다 치즈 볶음밥도 맛있었어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>역시 곱창은 강남곱 ㅠㅠ 소주 부르는맛이예요오늘 비도오는데 제대로 배터지게 먹고왓어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>음식은 평범하나 직원들이 매우 불친절합니다문래 곱 너무 맛있게 먹었어서 일부러 찾아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>모둠이랑 라면 다 너무너무 맜있어요사람들이 많으니 꼭 미리 예약하고 가세요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  y                                            ko_text\n",
       "0    5.0  1                                       분위기 맛 서비스 최고\n",
       "1    5.0  1             곱창 맛집 갈때마다 만족스러운 곱창집입니다 치즈 볶음밥도 맛있었어요 \n",
       "2    5.0  1  역시 곱창은 강남곱 ㅠㅠ 소주 부르는맛이예요오늘 비도오는데 제대로 배터지게 먹고왓어...\n",
       "3    1.5  0  음식은 평범하나 직원들이 매우 불친절합니다문래 곱 너무 맛있게 먹었어서 일부러 찾아...\n",
       "4    5.0  1          모둠이랑 라면 다 너무너무 맜있어요사람들이 많으니 꼭 미리 예약하고 가세요"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 함수를 적용하여 리뷰에서 한글만 추출\n",
    "df['ko_text'] = df['review'].apply(lambda x: text_cleaning(x))\n",
    "del df['review']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 형태소 단위로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "!set java_home=C:\\Program Files\\Java\\jdk-14.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\programdata\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in c:\\programdata\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['곱창/Noun', '맛집/Noun', '갈/Verb', '때/Noun', '마다/Josa', '만족스러운/Adjective', '곱창/Noun', '집/Noun', '입니다/Adjective', '치즈/Noun', '볶음밥/Noun', '도/Josa', '맛있었어요/Adjective']\n"
     ]
    }
   ],
   "source": [
    "# konlpy라이브러리로 텍스트 데이터에서 형태소를 추출\n",
    "def get_pos(x):\n",
    "    tagger = Okt()\n",
    "    pos = tagger.pos(x)\n",
    "    pos = ['{}/{}'.format(word,tag) for word, tag in pos]\n",
    "    return pos\n",
    "\n",
    "# 형태소 추출 동작 테스트\n",
    "result = get_pos(df['ko_text'][1])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [분류 모델의 학습 데이터로 변환하기]\n",
    "##### corpus index 생성하기\n",
    "    CountVectorizer 클래스의 tokenizer 파라미터는 텍스트 데이터의 전처리 방식을 입력하는 것이고, 이 객체에 df['ko_text'].tolist()을 입력값으로 fit_transform을 실행하면 학습 데이터셋을 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 형태소를 벡터 형태의 학습 데이터셋(X 데이터)으로 변환\n",
    "index_vectorizer = CountVectorizer(tokenizer = lambda x: get_pos(x))\n",
    "X = index_vectorizer.fit_transform(df['ko_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472, 2413)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'분위기/Noun': 1072, '맛/Noun': 766, '서비스/Noun': 1172, '최고/Noun': 2098, '곱창/Noun': 190, '맛집/Noun': 807,..\n"
     ]
    }
   ],
   "source": [
    "#피처 생성에 사용된 말뭉치\n",
    "#ex) '분위기' 형태소를 포함한 텍스트라면 1072번 피처의 벡터값은 1\n",
    "print(str(index_vectorizer.vocabulary_)[:100]+\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분위기 맛 서비스 최고\n",
      "  (0, 2098)\t1\n",
      "  (0, 1172)\t1\n",
      "  (0, 766)\t1\n",
      "  (0, 1072)\t1\n"
     ]
    }
   ],
   "source": [
    "#'분위기', '맛', '서비스', '최고' 라는 4개의 형태소로 구성된 텍스트 데이터가 있다고 할 때, 변환된 학습 데이터셋에서는 2098, 1172, 766, 1072번 위치의 X피처가 1로 채워진 데이터가 된다.\n",
    "print(df['ko_text'][0])\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 데이터에 중복되는 형태소가 있다면? => 이를 해결하기 위해 TF-IDF(Term Frequency - Inverse Document Frequency) 사용\n",
    "### TF-IDF : 다른 문서들에서는 등장하지 않았지만 현재 문서에는 많이 등장하는 단어를 의미하며, 그 단어가 현재 문서에서 얼마나 중요한지를 피처로 나타낼 수 있는 방법\n",
    "    ex) 1번 텍스트에서 '맛집'이라는 단어가 3번, 모든 데이터에서 '맛집'이 10번 등장한다고 할 때, 1번 문서에서 '맛집'의 TF 값은 3, IDF 값은 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# TF-IDF 방법으로, 형태소를 벡터 형태의 학습 데이터셋(X 데이터)으로 변환\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "X = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(472, 2413)\n",
      "  (0, 1072)\t0.5775860694563271\n",
      "  (0, 766)\t0.3924161043407496\n",
      "  (0, 1172)\t0.43081880116706756\n",
      "  (0, 2098)\t0.571663444681389\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# [Step3. 분류] : 긍정 부정 리뷰 분류하기\n",
    "### [분류 모델링] - 분류 모델 학습\n",
    "##### 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 2413)\n",
      "(142, 2413)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.89\n",
      "Precision : 0.887\n",
      "Recall : 1.000\n",
      "F1 : 0.940\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 로지스틱 회귀모델을 학습\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "y_pred_probability = lr.predict_proba(x_test)[:,1]\n",
    "\n",
    "# 로지스틱 회귀모델의 성능을 평가\n",
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 실행 결과를 보면, 대부분의 평가 수치가 매우 높다. 이렇게 비정상적으로 높은 경우, 모델의 평가방법이나 과정을 의심해볼 필요가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  16]\n",
      " [  0 126]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion Matrix 출력\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이 분류 모델은 모든 데이터를 '1'로 예측하고 있다. 모델이 하나의 결과만을 예측하도록 잘못된 학습을 한 것이다. 이를 '클래스의 불균형 문제'라고 한다.\n",
    "### 이는 데이터의 Positive sample(1)과 Negative sample(0)의 비율이 크게 차이나는 경우에 발생. 적절한 샘플링 방법을 통해 해결해야함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [분류 모델 개선]\n",
    "##### 클래스 불균형 문제 해결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    422\n",
       "0     50\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y가 0과 1을 각각 얼마나 가지고 있는지 확인\n",
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 비율로 랜덤 샘플링을 수행 - y가 1, 0인 샘플을 임의로 50개씩 추출\n",
    "positive_random_idx = df[df['y']==1].sample(50, random_state=30).index.tolist()\n",
    "negative_random_idx = df[df['y']==0].sample(50, random_state=30).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 2413)\n",
      "(30, 2413)\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 데이터로 데이터셋을 나눈다. - 다시 학습 데이터셋 70개, 테스트 데이터셋 30개로 분리한다.\n",
    "random_idx = positive_random_idx + negative_random_idx\n",
    "sample_X = X[random_idx, :]\n",
    "y = df['y'][random_idx]\n",
    "x_train, x_test, y_train, y_test = train_test_split(sample_X, y, test_size=0.30)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "##### Logistic Regression 다시 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.60\n",
      "Precision : 0.520\n",
      "Recall : 1.000\n",
      "F1 : 0.684\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀모델을 다시 학습\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "y_pred_probability = lr.predict_proba(x_test)[:,1]\n",
    "\n",
    "# 학습한 모델을 테스트 데이터로 평가\n",
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 12]\n",
      " [ 0 13]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix 출력\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이전보다 모델의 정확도는 떨어졌지만, 납득할 수 있을 정도의 성능으로 변했다. Confusion Matrix에서도 0과 1 두 클래스를 비슷한 비율로 예측하고 있다.\n",
    "### 이처럼 분류 모델의 평가 척도는 데이터셋의 샘플링 방법에 따라 성능과 기준이 달라질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# [Step4. 활용] : 중요 키워드 분석\n",
    "### [회귀 모델의 피처 영향력 추출]\n",
    "#### 양수인 피처들은 리뷰에서 긍정적으로 판단되는 형태소이며, 음수인 피처들은 리뷰에서 부정적으로 판단되는 형태소이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 2413 artists>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23f56676fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습한 회귀 모델의 계수를 출력\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "plt.bar(range(len(lr.coef_[0])), lr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [중요 피처의 형태소]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 긍정 형태소와 부정 형태소를 출력하기 위해 계수를 기준으로 형태소를 정렬 -> 정렬된 벡터는 index_vectorizer 객체에 다시 결과를 맵핑 -> 계수가 높은 순서대로 형태소 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.37485737997848656, 766), (0.3686337372925578, 329), (0.3523885195598684, 431), (0.34874013867657605, 9), (0.34470989169585065, 562)]\n",
      "[(-0.40102720060539343, 172), (-0.40481133247499834, 739), (-0.4250315872991918, 733), (-0.46615910635415037, 1342), (-0.5445990721836287, 1633)]\n"
     ]
    }
   ],
   "source": [
    "# 긍정 형태소와 부정 형태소를 출력하기 위해 계수를 기준으로 형태소를 정렬. \n",
    "print(sorted(((value, index) for index, value in enumerate(lr.coef_[0])), reverse=True)[:5])\n",
    "print(sorted(((value, index) for index, value in enumerate(lr.coef_[0])), reverse=True)[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 모델의 계수를 높은 순으로 정렬\n",
    "coef_pos_index = sorted(((value, index) for index, value in enumerate(lr.coef_[0])), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1072: '분위기/Noun', 766: '맛/Noun', 1172: '서비스/Noun', 2098: '최고/Noun', 190: '곱창/Noun', 807: '맛집/Noun',..\n"
     ]
    }
   ],
   "source": [
    "# 회귀 모델의 계수를 index_vectorizer에 맵핑하여, 어떤 형태소인지 출력할 수 있게 한다.\n",
    "invert_index_vectorizer = {v: k for k, v in index_vectorizer.vocabulary_.items()}\n",
    "\n",
    "# 계수가 높은 순으로, 피처에 형태소를 맵핑한 결과 출력. 계수가 높은 피처는 리뷰에 긍정적인 영향을 주는 형태소라고 할 수 있다.\n",
    "print(str(invert_index_vectorizer)[:100]+'..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맛/Noun 0.37485737997848656\n",
      "깔끔하고/Adjective 0.3686337372925578\n",
      "너무/Adverb 0.3523885195598684\n",
      "ㅎㅎ/KoreanParticle 0.34874013867657605\n",
      "도/Josa 0.34470989169585065\n",
      "최고/Noun 0.3404222944286197\n",
      "조아용/Adjective 0.3396258204608534\n",
      "되게/Adverb 0.310182933546223\n",
      "분위기/Noun 0.300846445173364\n",
      "도/Noun 0.284396445506478\n",
      "좋았습니다/Adjective 0.28103511119193253\n",
      "까지/Josa 0.2699281405711296\n",
      "갑니다/Verb 0.2690114407058459\n",
      "친절하십니다/Adjective 0.2635644899297846\n",
      "엄청/Adverb 0.2619901217160583\n",
      "ㅠ/KoreanParticle 0.2567546593357127\n",
      "인분/Noun 0.2524449164686272\n",
      "ㅎㅎㅎ/KoreanParticle 0.2443987661689795\n",
      "늘/Noun 0.24072738270365965\n",
      "잇어요/Verb 0.23495170427282683\n"
     ]
    }
   ],
   "source": [
    "# 상위 20개 긍정 형태소를 출력\n",
    "for coef in coef_pos_index[:20]:\n",
    "    print(invert_index_vectorizer[coef[1]], coef[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "못/VerbPrefix -0.21999059885352532\n",
      "아닌건/Adjective -0.22193298042578927\n",
      "비싸고/Adjective -0.22193298042578927\n",
      "짠듯/Verb -0.23400500402355393\n",
      "질/Noun -0.24210780136478363\n",
      "에어컨/Noun -0.2423433009888524\n",
      "북적/Noun -0.24636279243367815\n",
      "가/Josa -0.25286201638413075\n",
      "맛있었습니다/Adjective -0.2838062042298582\n",
      "이/Josa -0.28408568905945564\n",
      "에/Josa -0.30366412428854245\n",
      "아쉽습니다/Adjective -0.3296718175883455\n",
      "자리/Noun -0.3446636114536559\n",
      "별로/Noun -0.350073283111719\n",
      "굳/Adjective -0.37405544841310945\n",
      "고기/Noun -0.40102720060539343\n",
      "만족했습니다/Adjective -0.40481133247499834\n",
      "만족합니다/Adjective -0.4250315872991918\n",
      "안/VerbPrefix -0.46615910635415037\n",
      "은/Josa -0.5445990721836287\n"
     ]
    }
   ],
   "source": [
    "# 상위 20개 부정 형태소를 출력\n",
    "for coef in coef_pos_index[-20:]:\n",
    "    print(invert_index_vectorizer[coef[1]], coef[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `[미니 퀴즈 - 4.3]`\n",
    "- `피처 영향력에 따라 정렬된 형태소에서, 품사별 긍정 형태소 10개와 부정 형태소 10개를 탐색해 보세요.` \n",
    "    - “/”로 구분되어있는 정보를 활용하여 품사별 형태소를 추출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_list = []\n",
    "adj_list = []\n",
    "for coef in coef_pos_index:\n",
    "    category = invert_index_vectorizer[coef[1]].split('/')[1]\n",
    "    if category == 'Noun':\n",
    "        noun_list.append((invert_index_vectorizer[coef[1]], coef[0]))\n",
    "    elif category == 'Adjective':\n",
    "        adj_list.append((invert_index_vectorizer[coef[1]],coef[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('맛/Noun', 0.37485737997848656),\n",
       " ('최고/Noun', 0.3404222944286197),\n",
       " ('분위기/Noun', 0.300846445173364),\n",
       " ('도/Noun', 0.284396445506478),\n",
       " ('인분/Noun', 0.2524449164686272),\n",
       " ('늘/Noun', 0.24072738270365965),\n",
       " ('사람/Noun', 0.22182703268100742),\n",
       " ('집/Noun', 0.2150393976860301),\n",
       " ('굿/Noun', 0.19773332954744902),\n",
       " ('매장/Noun', 0.19754104725308308)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('깔끔하고/Adjective', 0.3686337372925578),\n",
       " ('조아용/Adjective', 0.3396258204608534),\n",
       " ('좋았습니다/Adjective', 0.28103511119193253),\n",
       " ('친절하십니다/Adjective', 0.2635644899297846),\n",
       " ('괜찮아요/Adjective', 0.2272789640944945),\n",
       " ('더웠어요/Adjective', 0.1940388835936287),\n",
       " ('좋고/Adjective', 0.18276993093587138),\n",
       " ('괜찮네요/Adjective', 0.17323798931536477),\n",
       " ('입니다요/Adjective', 0.16749105771606543),\n",
       " ('좋네요/Adjective', 0.15574493631308606)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
